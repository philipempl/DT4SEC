<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">(Do Not) Trust in Ecosystems</title>
			</titleStmt>
			<publicationStmt>
				<publisher>IEEE</publisher>
				<availability status="unknown"><p>Copyright IEEE</p>
				</availability>
				<date type="published" when="2019-05">2019-05</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Emilia</forename><surname>Cioroaica</surname></persName>
							<email>emilia.cioroaica@iese.fraunhofer.de</email>
							<affiliation key="aff0">
								<orgName type="department">Embedded Systems Quality Assurance Fraunhofer IESE</orgName>
								<address>
									<settlement>Kaiserslautern</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Kuhn</surname></persName>
							<email>thomas.kuhn@iese.fraunhofer.de</email>
							<affiliation key="aff1">
								<orgName type="department">Embedded Systems Fraunhofer IESE</orgName>
								<address>
									<settlement>Kaiserslautern</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Barbora</forename><surname>Buhnova</surname></persName>
							<email>buhnova@mail.muni.cz</email>
							<affiliation key="aff2">
								<orgName type="department">Faculty of Informatics Masaryk University Brno</orgName>
								<address>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">(Do Not) Trust in Ecosystems</title>
					</analytic>
					<monogr>
						<title level="m">2019 IEEE/ACM 41st International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)</title>
						<imprint>
							<publisher>IEEE</publisher>
							<date type="published" when="2019-05" />
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/icse-nier.2019.00011</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-06-09T12:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Smart Ecosystems</term>
					<term>Automotive</term>
					<term>Virtual Evaluation</term>
					<term>Building Trust</term>
					<term>Malicious Behavior</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the context of Smart Ecosystems, systems engage in dynamic cooperation with other systems to achieve their goals. Expedient operation is only possible when all systems cooperate as expected. This requires a level of trust between the components of the ecosystem. New systems that join the ecosystem therefore first need to build up a level of trust. Humans derive trust from behavioral reputation in key situations. In Smart Ecosystems (SES), the reputation of a system or system component can also be based on observation of its behavior.</p><p>In this paper, we introduce a method and a test platform that support virtual evaluation of decisions at runtime, thereby supporting trust building within SES. The key idea behind the platform is that it employs and evaluates Digital Twins, which are executable models of system components, to learn about component behavior in observed situations. The trust in the Digital Twin then builds up over time based on the behavioral compliance of the real system component with its Digital Twin. In this paper, we use the context of automotive ecosystems and examine the concepts for building up reputation on control algorithms of smart agents dynamically downloaded at runtime to individual autonomous vehicles within the ecosystem.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Until recently, the software architectures of automotive platforms focused solely on the static deployment of control functions. Control functions were deployed and integrated by engineers of automotive Original Equipment Manufacturers (OEMs). During system operation, only minor changes were performed. Future automotive platforms based, e.g., on the new POSIX-based Adaptive AUTOSAR standard <ref type="bibr" target="#b0">[1]</ref> will support dynamic deployment of automotive smart agents. This will be an enabler for smart ecosystems, which comprise a changing number of participants pursuing different goals and interacting with each other to achieve these goals in the best possible manner. A smart ecosystem could, for example, force vehicles entering a city to download smart agents that activate a speed limit in these vehicles that allow a maximum of 30 km/h.</p><p>The resulting dynamic architectures will yield new challenges for the software engineering of ecosystems. For example, the admission of smart agents into existing systems will become a relevant future topic. The admission of a smart agent into an ecosystem will enable this component to join an ecosystem, and for example permit a smart agent to supervise specific control functions of a vehicle, such as ensuring silent operation at night. Ecosystem admission should be based on functional correctness and on trust in the thirdparty component entering the ecosystem. In our work, we focus on the latter, as building trust in ecosystem components requires a new approach to testing, one that predicts the trustworthiness of a component to handle situations properly, instead of testing its correct implementation.</p><p>In this paper we propose a virtual Hardware-in-the-Loop (vHiL) testbed that supports rapid runtime evaluation of smart agents in smart (automotive) ecosystems. Based on this testbed, we introduce a novel strategy for building trust in ecosystems and ecosystem components by computing information about the reputation of smart agents. To this end, we employ the concept of Digital Twins (DT) of smart agents, which are used during operation of the smart agents to assess their runtime behavior. The evaluation results are then used to override detected malicious behavior before it takes effect, and to build up agent reputation over time. In this paper, we outline the whole approach and propose a solution for two specific challenges associated with it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. EMERGING TRENDS</head><p>During the transition of individual embedded systems to ecosystem participants, formerly isolated systems are equipped with open interfaces that enable communication and collaboration. This opens up possibilities for achieving extended business goals and facilitating innovation, as third-party applications may connect to these systems. At the same time, however, it introduces new research challenges related to safety and security risks, especially in the context of safetycritical smart ecosystems. A safety-critical smart ecosystem, for example, needs to guarantee that the driving speeds in the vecinity of schools in cities are low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Formation of Digital Ecosystems</head><p>Considerable work has been done in analyzing and describing Software Ecosystems (SECOs) formed around software products <ref type="bibr" target="#b1">[2]</ref>. The recent classification from 2015 <ref type="bibr" target="#b2">[3]</ref> emerged from a similar classification of Systems of Systems <ref type="bibr" target="#b3">[4]</ref>. As presented by us in <ref type="bibr" target="#b4">[5]</ref>, there is a distinction between Smart Ecosystems (SES) and Software Ecosystems (SECOs). SES are formed around cyber-physical systems (CPS) and their software and hardware components can be provided by different actors, such as the government or an organization, but also by a software company or an individual developer.</p><p>The hardware-software interaction within an SES thus requires additional checks of trust.</p><p>The key difference between digital ecosystems and systems of systems is that digital ecosystems involve actors with goals, which significantly influences the dynamics within an ecosystem <ref type="bibr" target="#b5">[6]</ref>. In cooperation, the actors might have not only collaborative goals, but also competitive goals, which may influence the health of the ecosystem <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>. In smart ecosystems, where hardware and software components of cyberphysical systems are provided by different actors, malicious behavior can be introduced along with software components by actors who join a smart ecosystem based on declared collaborative goals, but who are actually acting in competition.</p><p>Until now, admission to a digital ecosystem has been based on the actors' commitment to published roadmaps organized and provided by an ecosystem orchestrator for the long term <ref type="bibr" target="#b8">[9]</ref>. Safety-critical ecosystems, however, are particularly faced with the challenge of intended malicious behavior which may be hidden in the smart agents. As a consequence, besides being functionally correct, a safety-critical ecosystem also needs to assess the participants' trustworthiness before granting them admission. Assessing the trustworthiness of ecosystem participants requires new platforms that enable behavior evaluation at runtime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Formation of Trust in Ecosystems</head><p>While the risks associated with maliciously behaving actors in smart ecosystems have been recognized there is still no satisfactory solution for the issue yet. We argue that one of the most promising directions in this context can be driven by the formation of trust in smart agents.</p><p>Looking at the beginnings of development of autonomic computing systems, reputation can be a good indicator of the level of trust in a system. The authors of <ref type="bibr" target="#b9">[10]</ref> propose the possibility to store information about a system's reputation in order to address the need for trustworthiness in potential partners. However, this approach implies the execution of a system's behavior in the real world and hence entails the risks associated with executing malicious behavior that can be introduced along with smart agents. A solution for building reputation in a system without executing its behavior in the real world has become possible by recent advancements in the field of automation. The notion of a Digital Twin (DT) has been introduced by NASA [11] as a realistic digital representation of a flying object used in lab-testing activities. Since then, the notion of DT has also been adopted in the emerging Industry 4.0 <ref type="bibr" target="#b11">[12]</ref> for representing the status of production devices and to enable forecast of change impacts.</p><p>While the concept of DT is so far only being employed for simulation and testing detached from object operation, we see great potential in the incorporation of its usage into an object's operation time (the smart agent in our case), which we are proposing in this paper. In this way, we can create safe conditions for building reputation via multiple observations of a component's behavior in specific situations. In the smart ecosystem domain, the reputation of a smart agent can be built based on collected evidence about the decisions that the smart agent makes in these specific situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHOD FOR BUILDING TRUST</head><p>In this section, we introduce our approach to building trust in smart agents, which is based on the concept of Digital Twins and their safe real-time evaluation during the runtime of smart agents. Although the approach is general, we narrow it down to the context of automotive smart ecosystems, which allows us to be more specific in the explanation.</p><p>In automotive smart ecosystems, a vehicle receives a new smart agent which interacts with the automotive control software as a black box. The vehicle executes this agent on one of its Electronic Control Units (ECU). Building trust in this black box requires reputation from a trusted source, in our case the ecosystem of the city where the car is driving. In order to build up this trust, our platform (introduced in Section IV) evaluates a DT of the smart agent in a virtual environment in three steps:</p><p>1) The smart agent is downloaded to the vehicle together with its corresponding DT. The DT is an executable description of the algorithm that can be controlled in a simulated environment. Complementary to the algorithm, the DT defines an acceptable behavior range for the combination of input and output values and the internal state of the algorithm. 2) Phase 1 of our approach validates both the correctness and the trustworthiness of the smart agent by evaluating its DT behavior in the context of a simulation. The DT shows a projection of the behavior of the smart agent's control algorithm in all situations. This projection yields an abstracted behavior that reflects the control algorithm's behavior with bounded accuracy. In this way, the process of building trust in the smart agent does not require software execution on a real ECU, but merely evaluation of the behavior of the DT in a secured virtual environment (cf. Fig. <ref type="figure" target="#fig_0">1</ref>. phase 1). 3) Phase 2 builds trust in the conformity of the smart agent with its DT (cf. Fig. <ref type="figure" target="#fig_0">1</ref>. phase 2). This phase requires execution of the smart agent on the ECU. Conformity is checked by validating the behavior of the DT against the behavior of the real smart agent. This also requires a trustworthy monitoring platform. In this paper, we focus on the concept of Phase 1. It can be realized with two possible simulation strategies: (1) Pure predictive simulation is based on a set of well-defined situations that evaluate DT behavior in a virtual environment, while (2) linked predictive simulation virtualizes the vehicle's current situation and predicts sensor data to reflect a forecast situation in the near future. Linked predictive simulation evaluates the DT in situations that are not covered by pure predictive simulation. For example, when approaching a crossing at an intersection, our platform monitors the DT. The system needs sufficient time to react to the decisions of the smart agent and to possibly override them. Therefore, the platform evaluates the smart agent's DT with faster simulation speed during For evaluating the outcome of a control algorithm, a holistic scenario of the situation in which the system operates needs to be created. When evaluation happens at runtime (i.e., linked predictive simulation), the situation encountered at runtime needs to be represented accurately. This is accomplished by using DTs of systems that are part of the ecosystem and form the technical situation in which the smart agents are evaluated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. TESTING PLATFORM</head><p>Our test platform evaluates the trustworthiness of a smart agent before it is fully admitted to a smart ecosystem. For this reason, it must ensure that the control algorithm under evaluation cannot detect that it is under evaluation, i.e., that it cannot distinguish whether it is interacting with a real system, or with a simulation model. This includes addressing the uncertainties of real and simulated sensors, as well as the creating realistic scenarios that accurately reflect the technical situation encountered at runtime or that are anticipated in the near future. Based on this, our platform needs to deploy mechanisms that accurately compute the level of trust in an agent.</p><p>The metamodel that describes the logical structure of our test platform is depicted in Fig. <ref type="figure" target="#fig_1">2</ref>. Smart agents are software components that are dynamically deployed on systems. Digital Twins represent the behavior of smart agents with bounded accuracy. DTs are necessary because when a smart agents trustworthiness is evaluated, its DT must not detect whether it is interacting with real or virtual entities. Consequently, malicious behavior will be visible in the virtual world before it takes effect in the real world.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. (Do Not) Trust the Virtual Evaluation</head><p>One possible sandboxing approach is to ensure that the smart agent cannot detect that it is under evaluation in a simulated environment. In our opinion, such a sandbox is almost impossible to create in a safe and secure manner if the smart agent can implement complete Turing behavior. Therefore, we propose reducing the expressiveness of the DT for the simulation. This assures that the DT cannot implement detection algorithms.</p><p>The simulation is a virtual representation of a vehicle that is composed of multiple Software Components that implement for example control software. Virtual HW Components are specialized software components that implement hardware models, for example sensors, actuators, microprocessors, memories, etc. Given the abstracted behavior of the virtualized hardware resources, the frequency and value range of the output signals, as well as signal quality can differ considerably from realworld components. This offers an opportunity to detect that the evaluation is happening in a virtual environment. Therefore, Output Processors as the interface between the DT and the hardware resource implement signal preprocessing.</p><p>Abstract platform simulations create the opportunity for malicious software algorithms to detect whether they are interacting with virtual components or real systems, e.g., by sending commands to challenge the platform and provoke known responses. For example, by monitoring response times, or monitoring the consistency of sensor signals, a DT can detect a simulation. Therefore, besides reducing the expressiveness of the language for programming a DT, we also need to reduce its abilities to monitor its surroundings. The Software Wrapper component provides mechanisms that assure that DTs are not able to retain their state, neither monitor nor observe the passing of time. The platform interface of the Communication Middleware permits only very specific and limited interactions between DTs and platforms. Furthermore, the Monitor Behavior of SW Component monitors the behavior of software components in order to detect suspicious interaction patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. (Do Not) Trust the Smart Agent</head><p>Trust in a smart agent is built up over time via the concept of reputation. Our platform enables predictive simulation, which involves the execution of algorithm behavior at much higher speeds than wall clock time, as well as simulation of the same situations over and over again. This detects, for example, hidden behavior whose activation is quite unlikely. The reputation of a smart agent is influenced by monitoring Functional Properties and Non Functional Properties, such as reaction times, of the smart agent behavior. Actors, i.e. organizations that provide the system or components and users define Expectations towards actors. The reputation of an actor is therefore also liked to the Expectations that another actor has in the context of a collaboration. Therefore, the reputation of an actor introducing a system to the market needs to be considered as well.</p><p>Smart agents start with an initial level of trust when they join the ecosystem. This level is updated according to evidence continuously derived from the virtual evaluation of the smart agents Digital Twins. This includes multiple behavior executions in a virtual environment, uncommon situations, reference behavior, or situations that have been recorded before. This increases the probability that malicious behavior will show up in simulations and not when controlling real systems.</p><p>V. DISCUSSION AND CONCLUSION Technological progress opens up opportunities for business growth but despite the existence of safety standards it also leads to higher safety and security risks. With every new major accident, standards are reconsidered and improved. However, the process of improving the standards takes much longer than the deployment of methods and tools that can reduce these risks. Deployment of platforms that enable virtual verification of smart agents at runtime represents our vision tackling risks and building trust in safety-critical ecosystems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. State of the Work and Preliminary Results</head><p>Our platform is based on FERAL simulator <ref type="bibr" target="#b12">[13]</ref> and comes as an extension of the platform we describe in <ref type="bibr" target="#b4">[5]</ref>, which enables testing of automotive smart ecosystems. The platform already supports the testing of control algorithms to avoid obstacles. Virtual entities and real world entities collaborate with each other within the platform to jointly avoid obstacles. Our method and platform extension presented in this paper enhance the level of trust in smart agents with special attention on the importance of performing trustworthy virtual evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Future and Ongoing Work</head><p>The scope of the entire concept encompasses many interesting research questions for further investigation such as (a) checking conformity between the DT and the smart agent and (b) creating Digital Twins that accurately represent the behavior of the smart agent. In addition, we are currently researching a DT language with reduced expressiveness for functional models. The language must not be Turing complete so that detection of simulated environments can be prevented, and it should enable identification of malicious smart agents based on their Digital Twins. Furthermore, our platform could identify situations in which malicious behavior is exposed. Future work will include the implementation of phase 2 which guarantees conformity of smart agents with DT behavior and implements countermeasures in case of non conforming behavior.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Phases of the Method</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Metamodel of the Test Platform@Runtime</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Consolidating AUTOSAR with Complex Operating Systems (AUTOSAR on Linux)</title>
		<author>
			<persName><forename type="first">Sherif</forename><surname>Aly</surname></persName>
		</author>
		<idno type="DOI">10.4271/2017-01-1617</idno>
		<ptr target="https://www.autosar.org/" />
	</analytic>
	<monogr>
		<title level="m">SAE Technical Paper Series</title>
				<imprint>
			<publisher>SAE International</publisher>
			<date type="published" when="2017-03-28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Revisiting software ecosystems Research: A longitudinal literature study</title>
		<author>
			<persName><forename type="first">Konstantinos</forename><surname>Manikas</surname></persName>
			<idno type="ORCID">0000-0001-8531-898X</idno>
		</author>
		<idno type="DOI">10.1016/j.jss.2016.02.003</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Systems and Software</title>
		<title level="j" type="abbrev">Journal of Systems and Software</title>
		<idno type="ISSN">0164-1212</idno>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="84" to="103" />
			<date type="published" when="2016-07" />
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Defining decision making strategies in software ecosystem governance</title>
		<author>
			<persName><forename type="first">K</forename><surname>Manikas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wnuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shollo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Copenhagen</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Systems Security Engineering Capability Maturity Model (SSECMM), Model Description, Version 1.1</title>
		<author>
			<persName><surname>Department Of Defense  Washington Dc</surname></persName>
		</author>
		<idno type="DOI">10.21236/ada330236</idno>
		<editor>1.0. Washington, DC, ODUSD(A and T)SSE</editor>
		<imprint>
			<date type="published" when="1997-06-16" />
			<publisher>Defense Technical Information Center</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Prototyping Automotive Smart Ecosystems</title>
		<author>
			<persName><forename type="first">Emilia</forename><surname>Cioroaica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Bauer</surname></persName>
		</author>
		<idno type="DOI">10.1109/dsn-w.2018.00072</idno>
	</analytic>
	<monogr>
		<title level="m">2018 48th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reviewing the health of software ecosystems-a conceptual framework proposal</title>
		<author>
			<persName><forename type="first">K</forename><surname>Manikas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Workshop on Software Ecosystems (IWSECO)</title>
				<meeting>the 5th International Workshop on Software Ecosystems (IWSECO)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="33" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Goals of Software Vendors for Partner Ecosystems – A Practitioner´s View</title>
		<author>
			<persName><forename type="first">Karl</forename><forename type="middle">M</forename><surname>Popp</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-13633-7_17</idno>
	</analytic>
	<monogr>
		<title level="m">Lecture Notes in Business Information Processing</title>
				<imprint>
			<publisher>Springer Berlin Heidelberg</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="181" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Ecosystem traps and where to find them</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Bosch</surname></persName>
			<idno type="ORCID">0000-0003-2854-722X</idno>
		</author>
		<author>
			<persName><forename type="first">Helena</forename><forename type="middle">Holmström</forename><surname>Olsson</surname></persName>
			<idno type="ORCID">0000-0002-7700-1816</idno>
		</author>
		<idno type="DOI">10.1002/smr.1961</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Software: Evolution and Process</title>
		<title level="j" type="abbrev">J Softw Evol Proc</title>
		<idno type="ISSN">2047-7473</idno>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">e1961</biblScope>
			<date type="published" when="2018-07-27" />
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">From integration to composition: On the impact of software product lines, global development and ecosystems</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petra</forename><surname>Bosch-Sijtsema</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jss.2009.06.051</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Systems and Software</title>
		<title level="j" type="abbrev">Journal of Systems and Software</title>
		<idno type="ISSN">0164-1212</idno>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="76" />
			<date type="published" when="2010-01" />
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The vision of autonomic computing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O</forename><surname>Kephart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chess</surname></persName>
		</author>
		<idno type="DOI">10.1109/mc.2003.1160055</idno>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<title level="j" type="abbrev">Computer</title>
		<idno type="ISSN">0018-9162</idno>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="50" />
			<date type="published" when="2003-01" />
			<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">National Aeronautics and Space Administration</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shafto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Doyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Glaessgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kemp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lemoigne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1007/springerreference_222298</idno>
	</analytic>
	<monogr>
		<title level="m">National Aeronautics and Space Administration</title>
				<imprint>
			<publisher>Springer-Verlag</publisher>
			<date>2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">About The Importance of Autonomy and Digital Twins for the Future of Manufacturing</title>
		<author>
			<persName><forename type="first">Roland</forename><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Von Wichert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><forename type="middle">D</forename><surname>Bettenhausen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ifacol.2015.06.141</idno>
	</analytic>
	<monogr>
		<title level="j">IFAC-PapersOnLine</title>
		<title level="j" type="abbrev">IFAC-PapersOnLine</title>
		<idno type="ISSN">2405-8963</idno>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="567" to="572" />
			<date type="published" when="2015" />
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Feralframework for simulator coupling on requirements and architecture level</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Forster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gotzhein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Formal Methods and Models for Codesign (MEMOCODE)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="11" to="22" />
		</imprint>
	</monogr>
	<note>Eleventh IEEE/ACM International Conference on</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
