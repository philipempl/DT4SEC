<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The fog computing/edge computing to leverage Digital Twin</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">J</forename><surname>Pushpa</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Jain University</orgName>
								<address>
									<settlement>Bangalore</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Kalyani</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">East-West College</orgName>
								<address>
									<settlement>Bangalore</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The fog computing/edge computing to leverage Digital Twin</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0065-2458</idno>
					</monogr>
					<idno type="DOI">10.1016/bs.adcom.2019.09.003</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-06-09T12:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Contents 1. Introduction 2. Illustrating the epoch-making IoT journey 2.1 It is all about the extreme and deeper connectivity 2.2 The humongous volumes of IoT data 2.3 Major IoT data types 3. The use cases of fog/edge computing 3.1 Smart homes 3.2 Smart grids 3.3 Smart vehicles 3.4 Smarter security 3.5 Smart buildings 4. Fog and edge computing on digital twin 4.1 Fog computing 4.2 Edge computing 5. Facets of digital twin 6. Collaboration of fog computing 7. Collaboration with edge computing 7.1 Edge computing 7.2 Collaboration 8. Use cases of digital twin collaborated with fog 8.1 Drone in agricultural field 8.2 Automotive industry 8.3 Windmill 8.4 Workplace 9. Benefits 10. Conclusion References Further reading About the authors</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Digital Twin is a facet of IoT which emerges as new requirements in the industries and a step toward new digital world. Digital Twin can be defined as virtual device or monitoring device of physical entity which can be adopted by all factors in the world. From 2002 to till today many blogs, articles and research papers are heading toward digital twin to understand its potentiality and applicability.</p><p>Majority of the cloud vendor are looking forward the cloud based service to digital twin which gives the facilities to share the resources, reuse the existing components and create the data-centric system.</p><p>The world is moving toward digitization where data transmission is high between the users and connected device and also many coordination device are increasing as end devices increases. Computing all those request by computing devices require high bandwidth and channels and also modulator to boost the signals if it approaches cloud. Cloud computing provides different services such as IaaS, SaaS and NaaS which can be applied to many industrial setting to facilitate the new technology. With the emergence of new trends and technologies in the recent years of which Cloud computing and Internet of Things are some of the widely used technologies of today. We have seen tremendous growth in the number of IoT devices and dependencies on these devices.</p><p>With the ever growing increase in the number of IoT devices in the industry as a result of which there is a huge data deluge. These massive amounts of data coming from the IoT devices which are at the edge of the networks need to be processed. For this, huge amounts of data need to be transferred to and from the data centers or the cloud over the network, pushing network bandwidth to the limit. Despite improvements in network technology, data centers cannot guarantee acceptable transfer rates and response times which may be critical for applications. Though Cloud provides different services the cost is also more in terms of delay, accessibility and throughput, the cause of those factors are distance, approach ability and its heavy resources. Digital Twin is a technique commonly implemented on IoT devices which are mostly defined in confined region and are low power devices. Hence cloud computing is not appropriate solution for those devices. Real-time data processing, easy access, high throughput, low latency and quick analysis are some of the prime parameter in digital twin and also for real-time device. Edge computing may be the solution for it. Framework of digital twin not only contains the components of physical entity but also integrate with current technology to project the possible cases.</p><p>Edge Computing is a cloud technology which is locally available in the HAN and PAN which is evolved to achieve prime parameter of network for real-time system. In other words, all the processing can be performed at a location which is physically closer to the data source itself thus leveraging bandwidth, speed, maintenance, automation, etc. In order to achieve this, we need a faster, cheaper and smarter approach than the traditional approach which typically gather data, send them through network to the cloud or other environments for processing. Edge computing platform provides some of capabilities to the edge devices which reduce the traffic toward cloud which intern reduces the number of coordinator and modulator in the network. The idea of pushing the computational services or functionalities either completely or partially to the edge of the network is Edge Computing. In this chapter we study about the Edge Computing for digital twin and also fog computing which increases the efficiency and response to edge device. Fog computing and edge computing are used interchangeably in cloud environment, but each look similar but operate differently.</p><p>Fog Computing is also a cloud technology in the LAN which act like an intermediate layer between edge devices and cloud devices. As discussed by pod group from IoT for all [1] fog computing is a mini cloud within a local area network which build a data center like cloud to services the multiple connected node in an intra-network.</p><p>In oracle document [2] regarding the attribute of physical model is mentioned such as name, location, sensor, observed and desired attributes. It is also important about other attributes need to consider such as the attributes of links such as rate of data transfer, data format, standards and also technology integration techniques should be specified.</p><p>In this chapter, we will discuss about the characteristic of Fog and Edge computing along their services on digital twin. And also the comparative studies to know the benefits of each other.</p><p>We also study about few of the use case of digital twin and some of the field it can be evolved. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Illustrating the epoch-making IoT journey</head><p>The mesmerizing number of smart sensors and actuators being deployed in specific environments ultimately produces massive volumes of data and currently, the collected data is faithfully transmitted over the internet or any private network to faraway cloud infrastructures in order to be concertedly and calculatedly crunched to extract exceptional insights. As we all know, clouds are the best bet for doing the batch or historical processing through the renowned Hadoop framework. That is, cloud-based analytics is the overwhelming practice. However, the emerging trend is to come with micro-scale clouds in between the ground-level sensors and the cyber-level cloud applications toward fog analytics. This specialized cloud, which is being formed out of networked and resource-intensive devices in that environment, takes out the constricting stress on the traditional clouds. The proximate processing gets accomplished through these micro-clouds whereas the device data security and privacy is maintained. This kind of cloud-in-the-middle approach is capable of unearthing fresh IoT use cases. As any micro-cloud is very near the data-emitting sensors and sensors-attached assets, the faster processing and response are being achieved in an affordable fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">It is all about the extreme and deeper connectivity</head><p>As the inventive paradigm of networked embedded devices expands into multiple business domains and industry verticals such as manufacturing facilities and floors, healthcare centers, retail stores, luxury hotels, spacious homes, energy grids and transportation systems, there is a greater scope for deriving sophisticated applications not only for businesses but also for commoners. The world is tending toward the connected world. Recent devices come with the connectivity feature and there are a vast number of hitherto unconnected legacy devices. Further on, there are resource-constrained devices such as heart rate monitors to temperature &amp; humidity sensors, in plenty and enabling them to be integrated with other devices and web applications is definitely a big challenge. Thus, connectivity solutions and platforms are being brought in to enable every tangible device to be connected. The connectivity is not only with adjacent devices in the vicinity but also with the remotely held applications and data sources on the web/cloud.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The humongous volumes of IoT data</head><p>We have been fiddling with transaction systems extensively. The IT infrastructures, platforms, and applications are designed to be appropriate for streamlining and speeding up transactions. However, with the faster penetration of devices and digitized entities, there is a relook. That is, operational systems are becoming more prevalent and prominent. In the impending IoT era, a sensor or smart device that is monitoring temperature, humidity, vibration, acceleration or numerous other variables could potentially generate data that needs to be handled by back-end systems in some way every millisecond. For example, a typical Formula One car already carries 150-300 sensors and more controllers, sensors, and actuators are being continuously incorporated to bring in more automation. Today, these hundred sensors already capture data in milliseconds. The racecars generate 100-200 KBs of data per second, amounting to several terabytes in a racing season. There are twin challenges for back-end systems. Not only the storage concern but also the real-time processing of data is also equally important. That is, missing a few seconds of sensor data or being unable to analyze it efficiently and rapidly, can lead to risks and in some cases, to disasters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Major IoT data types</head><p>There are three major data types that will be common to most IoT projects:</p><p>Measurement data: Sensors monitor and measure the various parameters of the environment as well as the states of physical, mechanical, electrical and electronics systems. Heterogeneous and multiple sensors read and transmit data very frequently and hence with a larger number of sensors and frequent readings, the total data size is bound to grow exponentially. This is the crux of the IoT era. A particular company in the oil and gas space is already dealing with more than 100 TB of such data per day. Event data: Any status change, any break-in of the threshold value, any noteworthy incident or untoward accident, and any decision-enabling data are simply categorized event data. With devices assisting people in their daily assignments and engagements, the number of events is likely to shoot up. We have powerful simple and complex event processing engines in order to discover and disseminate knowledge out of event data.</p><p>Interaction and transaction data: With the extreme and deeper connectivity among devices, the quality and quantity of purpose-specific interactions between devices are going to be greater. Several devices with unique functionality can connect and collaborate for achieving composite functions. The transaction operations are also enabled in devices. Not only inter-device communication but also human-device communication is fairly happening. Diagnostics data: The delectable advancements in the IoT domain has led to millions of networked embedded devices and smart objects, information, transactional, analytical and operational systems. There are online, off-premise, and on-demand applications, data sources, and services in plenty. The application portfolio is consistently on the rise for worldwide enterprises. There are software infrastructure solutions, middleware, databases, data virtualization and knowledge visualization platforms, and scores of automation tool. The health of each of these systems is very important for the intended success of any business transaction. Diagnostics is the type of data that gives an insight into the overall health of a machine, system or process. Diagnostic data might not only show the overall health of a system but also show whether the monitoring of that system is also working effectively. Precisely speaking, the IoT data is going to be big and we have techniques and platforms for big data processing. However, the intriguing challenge is to do real-time processing of IoT big data. Researchers are on the job to unearth path-breaking algorithms to extract timely insights out of big data. Fog computing is one such concept prescribed as a viable and venerable answer for the impending data-driven challenges.</p><p>The IoT is turning out to be a primary enabler of the digital transformation of any kind of enterprising businesses. Companies are eagerly looking toward pioneering digital technologies to create and sustain their business competitiveness. The IoT and other digital technologies are helping companies to facilitate process enhancement, create newer business models, optimize the IT infrastructures, bring forth competent architectures, empower workforce efficiency and innovation, etc. The IoT closes down the gap between the physical and cyber worlds. Helps connect physical and digital environments. Data collected from connected devices are subjected to a variety of investigations to extract dependable insights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The use cases of fog/edge computing</head><p>The rapid growth of personal, social and professional devices in our daily environments has seeded this inimitable computing style.</p><p>The communication becomes wireless, sensors and devices are heterogeneous and large in number, geo-distribution becomes the new normal, the interconnectivity and interactions among various participants emit a lot of data, etc. The amount of data getting generated and gathered at the edge of the network is really massive in volumes.</p><p>Usually, this data is transported back to the cloud for storage and processing, which incidentally requires high bandwidth connectivity. In order to save network bandwidth, there is a valid proposition of using a moderately sized platform in between to do a kind of pre-processing in order to filter out the flabs. Differently enabled cameras, for example, generate images and videos that would aggregate easily in the range of terabytes. Instead of clogging expensive and scarce network bandwidths, a kind of fog/edge processing can be initiated to ease networks. That is, reasonably powerful devices in the environment under monitoring can be individually or collectively leveraged to process cameras-emitted files in real-time. That is, the data gleaned can be subsequently segmented and shared to different devices in the vicinity in order to do the distributed processing quickly. As we all know, with more devices joining in the mainstream computing and the amount of data getting stocked is growing exponentially, the distributed computing concept has soared in the recent past and is being touted as the mandated way forward for the data-centric world.</p><p>There are a number of convincing use cases for fog/edge computing. Fog devices locally collect, cleanse, store, process, and even analyze data in order to facilitate real-time analytics toward informed decisions. There are research papers describing how connected vehicles, smart grids, wireless sensor and actuator networks, etc., are more right and relevant for people with the fast-moving fog computing paradigm. Smart building, manufacturing floors, smart traffic and retail, and smart cities are some of the often-cited domains wherein the raging fog idea chips in with real benefits. Augmented reality (AR), content delivery and mobile data analytics are also very well documented as the direct beneficiaries of fog computing. One use case for fog computing is a smart traffic light system, which can change its signals based on surveillance of incoming traffic to prevent accidents or reduce congestion. Data could also be sent to the cloud for longer-term analytics. Other use cases include rail safety; power restoration from a smart grid network; and cybersecurity. There are connected cars (for vehicle-to-vehicle and vehicle-to-cloud communication); and in smart city applications, such as intelligent lighting and smart parking meters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Smart homes</head><p>There is a home security application profoundly discussed in a research paper. As we all know, there is a myriad of home security products (smart lock, video/audio recorder, security sensors and monitors; alarm, presence, occupancy, motion sensors, etc.). These are standalone solutions and due to disparate data transport protocols and data formats, these products do not interoperate with one another. However, the emergence and emancipation of fog computing have simplified the process of dynamically integrating these diverse security products in order to enhance the timeliness and trustworthiness of any security information. The uniqueness of fog computing platform is that it can be flexibly deployed on a virtual machine or in a Docker container. Existing and new sensors and actuators register and get connected with the fog platform, which ensures a seamless and spontaneous interoperation between different and distributed devices and machines toward the goal. This ad hoc collaboration capability senses any kind of security threats and immediately stimulates the necessary countermeasures through connected actuators. Energy management, device clustering and coordination, ambient assisted living (AAL), activity recognition/context-awareness for formulating and firming up peoplecentric services, etc., are getting streamlined with the fog computing nuances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Smart grids</head><p>Smart electric grid is an electricity distribution network with smart meters deployed at various locations to measure the real-time power consumption level. A centrally hosted SCADA server frequently gathers and analyzes status data to send out appropriate information to power grids to adapt accordingly. If there is any palpable increment in power usage or any kind of emergency, it will be instantaneously conveyed to the power grid to act upon. Now with the fog idea, the centralized SCADA server can be supplemented by one or more decentralized microgrids. This salient setup improves scalability, cost-efficiency, security and rapid response of the power system. This also helps to integrate distributed and different power generators (solar panels, wind farms, etc.) with the main power grid. Energy load balancing applications may run on edge devices such as smart meters and microgrids. Based on energy demand, availability, and the lowest price, these devices automatically switch to alternative energies like solar and wind.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Smart vehicles</head><p>The fog concept can be extended to vehicular networks also. The fog nodes can be deployed along the roadside. The fog nodes can send to and receive information from vehicles. Vehicles through their in-vehicle infotainment systems can interact with the roadside fog systems as well as with other vehicles on the road. Thus, this kind of ad hoc networks leads to a variety of applications such as traffic light scheduling, congestion mitigation, precaution sharing, parking facility management, traffic information sharing, etc. A video camera that senses an ambulance flashing lights can automatically change streetlights to open lanes for the vehicle to pass through traffic. Smart streetlights interact locally with sensors and detect the presence of pedestrian and bikers, and measure the distance and speed of approaching vehicles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Smarter security</head><p>Security and surveillance cameras are being fitted in different important junctions such as airports, nuclear installations, government offices, retail stores, etc. Further on, nowadays smartphones are embedded with powerful cameras to click selfies as well as produce photos of others. Still, as well as running images can be captured and communicated to nearby fog nodes as well as to faraway cloud nodes in order to readily process the photos and compare them with the face images of radicals, extremists, fundamentalists, terrorists, arsonists, trouble-makers, etc., in the already stored databases. Further on, through image processing and analytics, it is possible to extract useful information in the form unusual gestures, movements, etc. All these empower security and police officials to proceed in their investigations with clarity and confidence. In Fig. <ref type="figure" target="#fig_5">3</ref> pictorially conveys how the fog cloud facilitates real-time sensor data processing and historical sensor data processing at nearby or faraway clouds (public, private and hybrid) (Fig. <ref type="figure" target="#fig_1">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Smart buildings</head><p>Like homes, office and corporate buildings are stuffed with a number of sensors for minute monitoring, precise measurement, and management. There is a school of thought that multiple sensor values, when blended, throw more accurate value. There are advanced sensor data fusion algorithms and hence, smart sensors and actuators work in tandem toward automating and accelerating several manual tasks. For providing a seamless and smart experience to employees and visitors, the building automation domain is on the fast trajectory with a series of innovations and improvisations in the IT space. That is, computing becomes pervasive, communication is ambient, sensing is ubiquitous, actuation is intelligently accomplished, etc. The computer vision and perception topics gather momentum, knowledge engineering and enhancement are becoming common and cheap and decision-enablement becomes perfect. The edge devices participating in and contributing to the edge cloud facilitate multiple things intelligently so that the strategic goal of building automation through networking and integration is getting accomplished.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Traditional approach: Manual operation</head><p>Today, a medium-sized office building could have hundreds of sensors on its equipment. A great example is chillers, a product needed to cool a building. The product manufacturer (http://www.johnsoncontrols.com/) monitors chillers remotely using predictive diagnostics to identify and solve issues before they become problems. The company uses internal operational data and historical records to better plan machine maintenance, leading to better operational efficiency and decreasing energy usage, in addition to increase reliability and equipment lifespan. Even better, the company has external data resources like weather patterns and grid demand costs to drive greater operational savings. There are several other industry verticals and business domains yearning to get immensely benefited out of all the decisive and delectable advancements in the field of fog computing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Fog and edge computing on digital twin</head><p>In many sectors like Business, IT, Industries and also in Power Management wants foster collaboration for making any critical decision toward the progress. Cloud Services, AI and Machine Learning are introduced by the technical folks to integrate technologies and satisfy their requirement. When the smart devices are introduced into the market to make the thing easy and connect anything anywhere, then the requirements toward technology increases in terms of performance, real-time response and resilience and fault tolerance. Hence, to achieve these parameter new concept is evolved on the basis divide and conquer approach.</p><p>As we discussed in Section 1, cloud computing provides centralized architecture and satisfy the above requirement but some of the limitation such as round trip time and heavy resources to approach cloud center such as bandwidth, gateways modulator require more which increase cost. To overcome this limitation Fog and Edge computing taken birth. As we see in Fig. <ref type="figure" target="#fig_2">2</ref>, fog computing is looking like cloud computing near the Smart device which are also known as IoT device and the edge computing are looking like as if cloud is integrated to those edge device.</p><p>If we observe keenly the diagram, number of gateway is more between IoT device to cloud and the link represent the bandwidth (green:high Bandwidth, Black:medium Bandwidth and Yellow:low Bandwidth)</p><formula xml:id="formula_0">Chiller product.</formula><p>required for data transmission is also high. This concludes that if the distance between the devices for data transmission is less than better to choose fog/edge computing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Fog computing</head><p>Fog computing is a distributed architecture which can provide the services such as computing, storage, communication and many other services like cloud center. These resources are available near the IoT/arduino/edge devices. It overcome the limitation of cloud computing such as:  </p><formula xml:id="formula_1">4.1.1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Connectivity.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Security.</head><p>Fog computing address it by placing the required services near the edge device. As discussed by Bonomi <ref type="bibr" target="#b0">[3]</ref>, Fog computing is a virtualized cloud center which collaborate and distributed its service to any new technology or a standards to make the connectivity stronger and quicker. Some of the characteristic of Fog computing are discussed below: • Support mobility.</p><p>• Scalability by using grid topology. • Performance with better response time.</p><p>• Heterogeneity by supporting different devices. The above-discussed features facilitate agile, pro activeness and logistical data for Artificial or Machine learning devices.</p><p>As we know that digital twin of any entity require enormous amount of data both the history and present data to predict and analysis the future consequences. Hence the internet and connectivity also play a major role in digital twin. Hence incorporating fog in digital twin make the process robust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Edge computing</head><p>Edge Computing is a technology which provides the data analyzing, storing and utilizing in edge devices. It does collecting, aggregating and communicating the data along with providing the intelligent logistic to give optimal solution. Edge computing is a form of cloud computing or called as micro-cloud services which is integrated in edge devices.</p><p>Just glace about the devices used around are smart, quick and robust, such as Google Home, Smart Home, Smart home appliances, Drones, Amazon Dash buttons and many more. A research group estimated about the drastic growth of these smart devices may cross around 75.44 billion by 2025.</p><p>One of the backbone technology is edge computing, it is a gateways between the edge device to connect internet with minor latency which is suitable for real-time applications.</p><p>Edge computing is capable to manage applications, provide security, connectivity and also scalability. It is not only the software component but also hardware which interact with user and makes faster decision. Some of the vendors for Edge computing [4] in markets are: And many more including Google, Cisco and Microsoft are providing the edge gateways and analytic.</p><p>The role of Edge computing is vital on digital twin, such as • Provides application logic to the components in a model. • Filters the streaming data before reaching to destination.</p><p>• Providing the diversified data to the components.</p><p>• Synchronization between the devices or components.</p><p>• Maintains the statistical information of devices.</p><p>• Easy access point.</p><p>• Peer-to-Peer connectivity through Mesh topology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Facets of digital twin</head><p>Digital twin is a virtual representation of physical devices used in most of the IoT device to build and engineer with defect proof model. Technically it is a concept to simulate each and every dynamical movement of data from electrons to elements. It not only simulate but also gives status and condition according to its load and age of the model.</p><p>Hence collaboration of Digital device with edge/fog computing with artificial intelligence makes model robust and perfect.</p><p>So the facet of digital twin is not only the simulated model but also dynamic model. Hence, it is device of • Prediction • Analyzer • Simulator • Projection • Demonstrator • Collaborator and many more (Fig. <ref type="figure" target="#fig_5">3</ref>) Those properties of digital twin proven that it can integrate with any standards and technology to build fault proof model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Collaboration of fog computing</head><p>Digital twin is an extended feature of IoT which provide deeper insight of any model to automate and re-engineer the existing model to fix the bugs and make it agile. As we discussed already about fog computing and its capabilities, Let's discuss the scope of collaboration of Fog computing with digital twin by discussing the step to build digital twin. Role of Fog computing bridge the gap between digital twin and internet.</p><p>Step 1: Construct the simulation model of physical models components.</p><p>Step 2: Store all the training data between components. (Storage)</p><p>Step 3: Sense all the external factor impact on model. (Connectivity with low latency)</p><p>Step 4: Compute the logic (Algorithms) for all if else statement. (Computing power)</p><p>Step 5: Identify the point of failure and rebind quickly. (Server/traditional structure)</p><p>Step 6: Provision for scalability through integration or coupling. (Standards)</p><p>Step 7: Finally resultant value impacts on markets. (Global view) In the above-discussed steps, the highlighted parameters are the external components or the facilities required by digital twin. Fog computing not only provides the cloud services such as computing, storage and infrastructure but also concentrate on performance and response time which is a prime factor in real-time application. As discussed in Augmented Reality system for industry shipyard [5] fog computing address the challenges such as transmission delay, network traffic latency are high in cloud and progressively less in fog computing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Collaboration with edge computing</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Edge computing</head><p>Edge computing is a distributed computing paradigm which brings data storage and computation or processing closer to the location where it is needed to improve response times and save bandwidth.</p><p>By pushing computation to the edge of the network it is possible to analyze data in real-time which is very much required in industries such as manufacturing, healthcare, telecommunication, finance, etc. Edge Computing is a mesh network of micro data centers that process or store critical data locally and push all the received data to central data centers or cloud storage repository (Fig. <ref type="figure" target="#fig_7">5</ref>).</p><p>An ideal situation for edge computing deployment would be in circumstances where IoT devices have poor network connectivity and also as it is not very efficient for IoT devices to be always connected to the cloud. Edge Computing can be used in areas such as financial services and manufacturing which are sensitive to latency. The latency of even milliseconds in processing of information may be untenable for such applications. Edge Computing reduces latency as data need not be transferred to the cloud or data center over the network for processing. The aim of Edge Computing is to push computation to the edge of the network away from data centers, exploiting the capabilities of smart objects, mobile phones and network gateways to provide services and processing on behalf of the cloud.</p><p>An example of Edge Computing deployment would be an oil rig in the ocean that has many sensors generating massive amounts of data which perhaps confirms the proper functioning of the rig. However, most of the data generated by those sensors may be inconsequential and hence doesn't have to be sent across the network as soon as it is produced. So, the local data computing system compiles the data and generates daily reports and sends it to the cloud or a central data center for storage, thus sending only important data and minimizing the amount of data transferred across the network, saving network bandwidth and also reducing latency.</p><p>Another example which explains the benefits of Edge Computing is the usage of Web Browser by internet users. There are hundreds and thousands of people who are connected to the internet at any given point of time. One most widely used application by these users is the Web Browser. The browsers are used to watch videos, for research, etc. The browsers are operating on more and more devices such as mobile phones, set-top boxes, stick PCs, etc. The usability and display speed of the web browser depends upon the performance of the device. If the performance is of these devices is not very efficient, the latency increases which can be very stressful for the user. Edge Computing can be deployed in order to overcome the latency thus created. An Edge server can be placed between the cloud and physically closer to the user. NTT has developed NTT Web Browser which can offload part of the work load of the devices to the edge servers. The processing is done by the edge servers freeing the device of the task, thus reducing latency. The content is displayed at a much faster rate than through the standard web browser Edge Computing dates back to 1990s and is still considered a new paradigm, despite its history. Edge is a new buzzword which is nothing but processing and analyzing data along the edge of a network, nearer to the point of data collection, so data becomes actionable. The objective of edge computing is to solve the proximity problem, thus solving latency problem. Since Edge Computing does not depend only on the cloud for processing, outage reduction and intermittent connectivity can be improved. Also, by ensuring reliable operations in remote locations unplanned downtime as well as server downtime can be avoided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Collaboration</head><p>We can maximize the benefits of Edge Computing by combining it with other technologies. One such collaboration by which businesses can derive advantage is by combining it with Digital Twin technology. Edge Computing has the potential to minimize risk in real-time where as Digital Twin can predict future events accurately which can benefit businesses to a great extent <ref type="bibr">[6]</ref>.</p><p>Digital Twin is a virtual or digitized model of a service, product or a process or any IoT. More than one digital twin can be developed for any particular object based on its industrial context. It is a virtual representation of the components and dynamics of the real world entity which facilitates operations of the product as well. Processing can be simulated using digital twin which can accurately predict product's behavior under different conditions such as weather changes or as they age. This will help in making required changes in the product and making it a better one <ref type="bibr">[5]</ref>.</p><p>Digital Twin provide significant advantages in a cloud-based environment. What if we deployed a digital twin along the edge of a network? Edge-deployed Digital Twin give way to new autonomous systemsreal-time artificial intelligent systems based on self-learning. By developing a virtual model of the physical asset, greater flexibility can be achieved to define, evolve, build and leverage twins for real-time IoT.</p><p>Digital Twins reside in, and is maintained in the cloud, fed with data from its environment through devices, sensors or simulations. Digital twins are used to understand past and present operations and to predict future events by leveraging with machine learning approaches to build a better system by detecting anomalies and forecasting failures. Edge Computing provides advanced processing and cloud-based analytics that enables faster and localized decision making at the edge <ref type="bibr">[1]</ref>. By deploying the digital twin at the edge will make it possible to build smarter applications. Moving the digital twin to the edge of the network facilitates smarter applications because:</p><p>• Reduction in latency: In a cloud-based digital twin, the delay caused due to cloud access is not acceptable. Edge-deployed digital twin reduces the latency and applications that require sub-second latencies can be derived. • Analytics generated by the digital twin can guide local control and vice versa. An anomaly that could cause a problem in future can be fixed without human intervention. • Using machine learning approach on streaming data, digital twin can evolve much faster and acquire the ability to self-learn. • Edge computing technology implements decentralization of data and distributed in the network, it will not be possible for hackers to corrupt data, also minimizing transfer of sensitive information over network and thus enhancing data security. Data Encoding and implementing Virtual Private Network becomes very important with the growth of Edge Computing technology <ref type="bibr" target="#b0">[3]</ref>. • Edge computing also facilitates scaling of IoT network much faster and as required [1]. Edge-deployed digital twin also provides business benefits such as: 2 Because cloud storage and analysis can be costly. Edge-deployed digital twin reduces cloud hosting costs as all the data need not be sent to the cloud. 2 As the data processing is performed at the edge of the network, the volume of data that has to be transmitted to the cloud reduces. 2 Sensitive data need not be sent to the cloud. 2 Analytics can be performed even when the digital twin is disconnected.</p><p>By merging these two emerging technologies, we can develop devices which can exhibit intelligence and possess immense decision making capabilities without human intervention. We can create a future which we have never imagined before. Many systems and products combining these two technologies have been developed and deployed in various areas of business which impart both tangible and intangible benefits to the organization. We shall discuss some of the Use Cases which substantiate the above statement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Use cases of digital twin collaborated with fog</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Drone in agricultural field</head><p>Drone is a flying agent to perform the specific task in any given area. Some of the experience shared by the students in IoT lab to design the drone fails successively in building process due to the imbalance in propeller and after they use the digital twin to simulate the drone and successfully built after simulating by providing proper parameter. This kind of experiment take place in many field to ripe the benefits of IoT devices. At the same time many new thoughts arrive as the requirement increases leads to the failure in existing IoT devices to support. Hence digital twin bridge the gap and collaborate with internet to provide the service on demand with micro latency through fog computing. As shown in Fig. <ref type="figure" target="#fig_8">6</ref>, Skyx's developed an drone for auto piloting in agricultural field to manages and monitors the crops development and also suitable for real-time controlling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Automotive industry</head><p>The automotive industry has introduced electric cars into the market in recent years. There has been a growing demand for these electric cars which were developed with a benevolent intent of saving the environment. Though these cars are currently manually driven, the industry is aiming at converting these manually driven cars to self-driven bots. Edge Computing and Simulation technologies can help bridge the gap and make the self-driven cars a reality <ref type="bibr">[6]</ref>. In cloud-based technology data processing and storage is done remotely, whereas in edge computing data is processed at a location which is in close physical proximity of the data source, facilitating transfer of data at a faster rate. Using this technology, cars could make decisions such as when to apply a break, to start driving or make turns, increase speed etc. much faster <ref type="bibr">[6]</ref>. By combining this with digital twin technology and simulation, future events can be predicted which can help the vehicles to navigate better and avoid collisions by making appropriate decisions whenever the need arises.</p><p>By enhancing this technology and implementing in the automotive industry, development costs can be reduced, efficiency improved and sustainability can be enhanced by the automobile manufacturers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Windmill</head><p>Consider the hypothetical situation of a Windmill where a hierarchy of digital twins can be used. In this example the digital twins are organized Self-driven car.</p><p>in a hierarchy where the low-level digital twin represents individual components and higher level digital twin represents sub-systems which control these devices. Twins at various levels send the messages downward to the lower levels for controlling as a result of which signals are generated that will be in turn sent to the devices. The application logic has to be divided between the cloud and the edge. Digital twins enable to successfully migrate low-level event handling operations to the edge and higher level digital twins can operate in the cloud or wherever the computing resources are located (Fig. <ref type="figure">7</ref>).</p><p>The use of digital twin technology does not require all device specific operations to be migrated to the edge of the network. Instead, the low-level twin can the functionalities of the device directly, and the high level twin implements machine learning approach and performs predictive analytics based on data received by the low-level twin. Thus, it is a good idea to move low-level twin to the edge and hence reduce response time and processing can be completed without any interruption. The high level twin can reside wherever the computing resources are located or in the cloud for the predictive analytics algorithm to be executed <ref type="bibr">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Low level Digital</head><note type="other">Blades Blade System Generators Control Panel Wind Mill</note><p>High level Digital Fig. <ref type="figure">7</ref> Windmill.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Workplace</head><p>The Workplace environment can be checked in real-time by deploying edge computing with digital twin technology. By creating virtual representations of buildings and office spaces and integrating it with edge computing, the environment can be monitored in real-time, potential risks and dangers can be avoided, suitable measures can be taken to avoid accidents and disasters. Few use cases have been discussed in the above section, but this is not all.</p><p>Although Edge Computing and Digital Twin technology are being implemented extensively distinctively in various sectors of business and industry, the combination of these two technologies are also finding way in today's business which can provide real-time, intelligent solutions to organizations. We will be heading toward a future which we have never experienced before.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Benefits</head><p>The collective data analysis to compare the performance on digital twin between cloud, fog and edge computing are carried out with the list of parameters such as: • Speed • Bandwidth • Response time • Latency • Throughput As shown in Fig. <ref type="figure" target="#fig_9">8</ref>, drastic improvement in edge computing with respect to the above listed network parameter signifies the integration of digital twin with Fog/Edge computing. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">Conclusion</head><p>The digital twin technology is to empower edge/fog devices to be intelligent in their actions and reactions. As the future beckons for edge/fog clouds for realizing and running real-time and insights-driven applications and services, the role and responsibility of having and using digital twins for all the participating physical twins are bound to go up in the days to come. Further on, the analytical capabilities of both physical and digital twins come handy in making edge/fog devices (physical twins) adaptive, adjustive and autonomous. This chapter is specially crafted in order to tell all about how the digital representation of edge devices is ultimately helping in empowering them intelligent in decisions, deals and deeds.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1</head><label>1</label><figDesc>Fig.1The fog ensures zero latency toward real-time applications.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2 Bandwidth utilization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>1.</head><label></label><figDesc>FUJITSU IoT Solution: It provides the edge computing to bridge the gap between operational and tradition device in industrial context. 2. FogHorn: It provides Edge computing for IoT. 3. Saguna: It provides Multiple-access Edge cloud. 4. ClearBlade: It orchestrate a multiple layer and edge computing devices.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(a) Prediction: Digital twin is a model which can take a data set of different pattern from machine data and experiment with data fusion to predict the possibilities. (b) Analyzer: Analyzing the gathered data from all the relevant component through any of the data science technique can give an appropriate input to predict. (c) Simulator: Digital twin is not just a simulator to simulate the system but also provides idea about upcoming challenges and also adopts the new properties to rebuild the model. (d) Projection: Projection is basically used by business process to integrates the requirements and trigger the solution if any needed. (e) Collaboration: Digital twin can collaborated with any technologies to bridge the gap between past and future. It can integrate with cloud/ fog/edge or any AI to improve the efficiency. (f ) Demonstrator: A sample model can be demonstrated and experiments with the available data for refinement. Fig. 4 visualizes the collaboration feature of digital twin.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3</head><label>3</label><figDesc>Fig. 3 Facet of digital twin.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 Digital twin collaboration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 (</head><label>5</label><figDesc>Fig. 5 (Top) Cloud computing and (bottom) edge computing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 6</head><label>6</label><figDesc>Fig.6Auto-piloting in agricultural field.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8</head><label>8</label><figDesc>Fig. 8 Response time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>From Myth to Manifest -Why Digital Twins Why Now...........? by Jonathan Lang</figDesc><table><row><cell>Manifestation.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Computing Fog Computing Fog Computing Fog Computing Edge Devices</head><label></label><figDesc>Limitation of cloud computing 1. Response time delay. 2. Bandwidth Utilization.</figDesc><table><row><cell>Cloud</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">J. Pushpa and S.A. Kalyani</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">The fog computing/edge computing to leverage Digital Twin</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>About the authors J. Pushpa is a research scholar in VTU Belgaum. Area of specialization is on software defined networking, edge computing and fog computing. Working experience in IT industry and in teaching organization, currently working as Assistant Professor in Jain University, Bangalore.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.A. Kalyani is serving as Assistant Professor in East West</head><p>College and has enormous knowledge in the area of artificial intelligence and working on data science.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Bonomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Milito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<title level="m">Sateesh Addepalli Cisco Systems Inc: Fog Computing and Its Role in the Internet of Things, 2012. 170 W Tasman Dr</title>
				<meeting><address><addrLine>San Jose, CA 95134, USA</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">El</forename><surname>Saddik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="343" to="357" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">C2PS: a digital twin architecture reference model for the cloud-based cyber-physical systems</title>
		<author>
			<persName><forename type="first">Masudul</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdulmotaleb</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName><surname>El Saddik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="2050" to="2061" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
